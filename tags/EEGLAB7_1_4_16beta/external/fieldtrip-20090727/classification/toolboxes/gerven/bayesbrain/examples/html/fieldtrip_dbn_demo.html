
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN">
<html xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   
      <!--
This HTML is auto-generated from an M-file.
To make changes, update the M-file and republish this document.
      -->
      <title>Using dynamic Bayesian networks together with FieldTrip data</title>
      <meta name="generator" content="MATLAB 7.6">
      <meta name="date" content="2008-12-02">
      <meta name="m-file" content="fieldtrip_dbn_demo"><style>

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head>
   <body>
      <div class="content">
         <h1>Using dynamic Bayesian networks together with FieldTrip data</h1>
         <introduction>
            <p>This example demonstrates how to use neuroimaging data obtained from FieldTrip together with the neurogm toolbox. In the example,
               we make use of covert attention data of one subject that has already been frequency analyzed. Note that this is trial based
               data so we can build finite size models that capture behaviour within a trial.
            </p>
            <p>The data consists of 7 different frequencies at 274 channels at time points [-0.5 0 0.5 1 1.5 2 2.5]. We can expect evoked
               response after the cue and alpha modulation after about 1 second
            </p>
            <p>In this particular example, we will construct a dynamic Bayesian network that captures the evolution over time of the random
               variables.
            </p>
            <p>Copyright (C) 2008  Marcel van Gerven</p>
         </introduction>
         <h2>Contents</h2>
         <div>
            <ul>
               <li><a href="#1">Create and use a DBN</a></li>
            </ul>
         </div>
         <h2>Create and use a DBN<a name="1"></a></h2><pre class="codeinput"><span class="keyword">function</span> fieldtrip_dbn_demo()
</pre><p>Load frequency data and convert the data to a format that can be used by NEUROGM. A Bayesian network is a static model, so
            we will take out the time data and focus only on the 12 Hz band in two channels in left and right hemisphere.
         </p><pre class="codeinput">load <span class="string">freqli</span>; <span class="comment">% left attention</span>
load <span class="string">freqri</span>; <span class="comment">% right attention</span>

<span class="comment">% left and right channels</span>
l = find(ismember(freqLI.label,<span class="string">'MLO32'</span>));
r = find(ismember(freqRI.label,<span class="string">'MRO32'</span>));

<span class="comment">% We take the log, center, and scale the data to make it better behaved</span>
<span class="comment">% Note that we add an arbitrary variable which will accommodate the discrete</span>
<span class="comment">% variable</span>
datal = squeeze(log(freqLI.powspctrm(:,[l r 1],3,:)));
datar = squeeze(log(freqRI.powspctrm(:,[l r 1],3,:)));
clear <span class="string">freqli</span>; clear <span class="string">freqri</span>;

<span class="comment">% Reshape so each time slice is concatenated after one another</span>
sz = size(datal);
datal = reshape(datal,[sz(1) prod(sz(2:end))]);
sz = size(datar);
datar = reshape(datar,[sz(1) prod(sz(2:end))]);

<span class="comment">% Each third variable is the discrete node</span>
datal(:,3:3:size(datal,2)) = 1;
datar(:,3:3:size(datar,2)) = 2;
</pre><p>Now we can create a very simple model that consists of one discrete parent (the attention condition) and two continuous children
            per slice
         </p><pre class="codeinput">data = [datal; datar];
clear <span class="string">datal</span>; clear <span class="string">datar</span>;
</pre><pre>Create a two-slice DBN where nodes in the second slice have
auto-connections</pre><pre class="codeinput">factors = cell(1,6);
factors{1} = gaussian_cpd(1,[],3,[0; 0],{[]; []},[1; 1]);
factors{2} = gaussian_cpd(2,[],3,[0; 0],{[]; []},[1; 1]);
factors{3} = multinomial_cpd(3,[],[0.5; 0.5]);
factors{4} = gaussian_cpd(4,1,6,[0; 0],{0; 0},[1; 1]);
factors{5} = gaussian_cpd(5,2,6,[0; 0],{0; 0},[1; 1]);
factors{6} = multinomial_cpd(6,3,[0.5 0.5; 0.5 0.5]);

<span class="comment">% optionally add names to the factors</span>
factors{1}.name = <span class="string">'MLO32'</span>;
factors{2}.name = <span class="string">'MRO32'</span>;
factors{3}.name = <span class="string">'orientation'</span>;
factors{3}.statenames = {<span class="string">'left attention'</span> <span class="string">'right attention'</span>};
factors{4}.name = <span class="string">'MLO32'</span>;
factors{5}.name = <span class="string">'MRO32'</span>;
factors{6}.name = <span class="string">'orientation'</span>;
factors{6}.statenames = {<span class="string">'left attention'</span> <span class="string">'right attention'</span>};
</pre><p>Create simple dynamic bayes net</p><pre class="codeinput">dbn = dbnet(factors);
</pre><p>Unroll it to accommodate all 7 slices</p><pre class="codeinput">dbn = dbn.unroll(7,-0.5:0.5:2.5);
</pre><p>Show the unrolled DBN</p><pre class="codeinput">dbn.write(<span class="string">'tmpdbn'</span>,<span class="string">'dot'</span>,<span class="string">'extension'</span>,<span class="string">'ps'</span>);
</pre><p>This is what the plot would look like</p>
         <p><img vspace="5" hspace="5" src="tmpdbn.jpg"> </p>
         <p>Treat DBN as BN</p><pre class="codeinput">bn = bayesnet(dbn);
</pre><p>Learn parameters which are coupled between slices</p><pre class="codeinput">bn = bn.learn_parameters(data);
</pre><p>plot parameter uncertainty for the first random variable</p><pre class="codeinput">mu = bn.factors{1}.ess.mu.value{1};
sigma = sqrt(bn.factors{1}.sigma2(1)/bn.factors{1}.ess.tau.value{1});
subplot(1,2,1);
fplot(@(x)(normpdf(x,mu,sigma)),[mu-3*sigma mu+3*sigma]);
title(<span class="string">'uncertainty in the mean'</span>);

a = bn.factors{1}.ess.rho.value{1}/2;
b = bn.factors{1}.ess.phi.value{1}/2;
s = bn.factors{1}.sigma2(1);
subplot(1,2,2);
fplot(@(x)((b^a/gamma(a)) * x^(-a-1)* exp(-b/x)),[s - s/2 s + s/2])
title(<span class="string">'uncertainty in the variance'</span>);
</pre><img vspace="5" hspace="5" src="fieldtrip_dbn_demo_01.png"> <p>show likelihood</p><pre class="codeinput">bn.loglik(data)
</pre><pre class="codeoutput">
ans =

 -20.925444249341489

</pre><p>compare without assuming that parameters are coupled between slices</p><pre class="codeinput">dbn = dbnet(factors,<span class="string">'coupled'</span>,false);
bn2 = bayesnet(dbn.unroll(7,-0.5:0.5:2.5));
</pre><p>show evolution of the mean and variance estimates for one variable</p><pre class="codeinput">bn2 = bn2.learn_parameters(data);
</pre><p>likelihood is a bit better without the coupling</p><pre class="codeinput">bn2.loglik(data)
</pre><pre class="codeoutput">
ans =

 -20.303893464533161

</pre><p>let's check the evolution of the means and standard deviations</p><pre class="codeinput">mus = zeros(2,2,7);
sds = zeros(2,2,7);
<span class="keyword">for</span> s=1:2
    <span class="keyword">for</span> j=1:7
        mus(s,1,j) = bn2.factors{(j-1)*3+s}.mu(1);
        mus(s,2,j) = bn2.factors{(j-1)*3+s}.mu(2);
        sds(s,1,j) = sqrt(bn2.factors{(j-1)*3+s}.sigma2(1));
        sds(s,2,j) = sqrt(bn2.factors{(j-1)*3+s}.sigma2(2));
    <span class="keyword">end</span>
<span class="keyword">end</span>

figure
subplot(1,2,1);
errorbar(-0.5:0.5:2.5,squeeze(mus(1,1,:)),squeeze(sds(1,1,:)));
hold <span class="string">on</span>;
errorbar(-0.5:0.5:2.5,squeeze(mus(1,2,:)),squeeze(sds(1,2,:)),<span class="string">'r'</span>);
title(<span class="string">'MLO32'</span>);
legend(<span class="string">'left attention'</span>,<span class="string">'right attention'</span>);

subplot(1,2,2);
errorbar(-0.5:0.5:2.5,squeeze(mus(2,1,:)),squeeze(sds(2,1,:)));
hold <span class="string">on</span>;
errorbar(-0.5:0.5:2.5,squeeze(mus(2,2,:)),squeeze(sds(2,2,:)),<span class="string">'r'</span>);
title(<span class="string">'MRO32'</span>);
legend(<span class="string">'left attention'</span>,<span class="string">'right attention'</span>);
</pre><img vspace="5" hspace="5" src="fieldtrip_dbn_demo_02.png"> <p>let's see how the variables depend on their past state</p><pre class="codeinput">betas = zeros(2,2,6);
<span class="keyword">for</span> s=1:2
    <span class="keyword">for</span> j=1:6
        betas(s,1,j) = bn2.factors{j*3+s}.beta{1};
        betas(s,2,j) = bn2.factors{j*3+s}.beta{2};
    <span class="keyword">end</span>
<span class="keyword">end</span>

figure
subplot(1,2,1);
plot(0:0.5:2.5,squeeze(betas(1,1,:)));
hold <span class="string">on</span>;
plot(0:0.5:2.5,squeeze(betas(1,2,:)),<span class="string">'r'</span>);
title(<span class="string">'MLO32'</span>);
legend(<span class="string">'left attention'</span>,<span class="string">'right attention'</span>);

subplot(1,2,2);
plot(0:0.5:2.5,squeeze(betas(2,1,:)));
hold <span class="string">on</span>;
plot(0:0.5:2.5,squeeze(betas(2,2,:)),<span class="string">'r'</span>);
title(<span class="string">'MRO32'</span>);
legend(<span class="string">'left attention'</span>,<span class="string">'right attention'</span>);
</pre><img vspace="5" hspace="5" src="fieldtrip_dbn_demo_03.png"> <p class="footer"><br>
            Published with MATLAB&reg; 7.6<br></p>
      </div>
      <!--
##### SOURCE BEGIN #####
%% Using dynamic Bayesian networks together with FieldTrip data
% This example demonstrates how to use neuroimaging data obtained from FieldTrip
% together with the neurogm toolbox. In the example, we make use of covert
% attention data of one subject that has already been frequency analyzed.
% Note that this is trial based data so we can build finite size models
% that capture behaviour within a trial.
%
% The data consists of 7 different frequencies at 274 channels at time
% points [-0.5 0 0.5 1 1.5 2 2.5]. We can expect evoked response after the
% cue and alpha modulation after about 1 second
%
% In this particular example, we will construct a dynamic Bayesian network 
% that captures the evolution over time of the random variables.
%
% Copyright (C) 2008  Marcel van Gerven
%

%% Create and use a DBN
function fieldtrip_dbn_demo()

%%
% Load frequency data and convert the data to a format that can be used by NEUROGM.
% A Bayesian network is a static model, so we will take out the time data
% and focus only on the 12 Hz band in two channels in left and right
% hemisphere.

load freqli; % left attention
load freqri; % right attention

% left and right channels
l = find(ismember(freqLI.label,'MLO32'));
r = find(ismember(freqRI.label,'MRO32'));

% We take the log, center, and scale the data to make it better behaved
% Note that we add an arbitrary variable which will accommodate the discrete
% variable
datal = squeeze(log(freqLI.powspctrm(:,[l r 1],3,:)));
datar = squeeze(log(freqRI.powspctrm(:,[l r 1],3,:)));
clear freqli; clear freqri;

% Reshape so each time slice is concatenated after one another
sz = size(datal);
datal = reshape(datal,[sz(1) prod(sz(2:end))]);
sz = size(datar);
datar = reshape(datar,[sz(1) prod(sz(2:end))]);

% Each third variable is the discrete node 
datal(:,3:3:size(datal,2)) = 1;
datar(:,3:3:size(datar,2)) = 2;

%%
% Now we can create a very simple model that consists of one discrete
% parent (the attention condition) and two continuous children per slice
data = [datal; datar];
clear datal; clear datar;

%%
%  Create a two-slice DBN where nodes in the second slice have
% auto-connections
factors = cell(1,6);
factors{1} = gaussian_cpd(1,[],3,[0; 0],{[]; []},[1; 1]);
factors{2} = gaussian_cpd(2,[],3,[0; 0],{[]; []},[1; 1]);
factors{3} = multinomial_cpd(3,[],[0.5; 0.5]);
factors{4} = gaussian_cpd(4,1,6,[0; 0],{0; 0},[1; 1]);
factors{5} = gaussian_cpd(5,2,6,[0; 0],{0; 0},[1; 1]);
factors{6} = multinomial_cpd(6,3,[0.5 0.5; 0.5 0.5]);

% optionally add names to the factors
factors{1}.name = 'MLO32';
factors{2}.name = 'MRO32';
factors{3}.name = 'orientation';
factors{3}.statenames = {'left attention' 'right attention'};
factors{4}.name = 'MLO32';
factors{5}.name = 'MRO32';
factors{6}.name = 'orientation';
factors{6}.statenames = {'left attention' 'right attention'};

%%
% Create simple dynamic bayes net
dbn = dbnet(factors);

%% 
% Unroll it to accommodate all 7 slices
dbn = dbn.unroll(7,-0.5:0.5:2.5);

%%
% Show the unrolled DBN

dbn.write('tmpdbn','dot','extension','ps');

%% 
% This is what the plot would look like
%
% <<tmpdbn.jpg>>

%%
% Treat DBN as BN
bn = bayesnet(dbn);

%%
% Learn parameters which are coupled between slices
bn = bn.learn_parameters(data);

%% 
% plot parameter uncertainty for the first random variable

mu = bn.factors{1}.ess.mu.value{1};
sigma = sqrt(bn.factors{1}.sigma2(1)/bn.factors{1}.ess.tau.value{1});
subplot(1,2,1);
fplot(@(x)(normpdf(x,mu,sigma)),[mu-3*sigma mu+3*sigma]);
title('uncertainty in the mean');

a = bn.factors{1}.ess.rho.value{1}/2;
b = bn.factors{1}.ess.phi.value{1}/2;
s = bn.factors{1}.sigma2(1);
subplot(1,2,2);
fplot(@(x)((b^a/gamma(a)) * x^(-a-1)* exp(-b/x)),[s - s/2 s + s/2])
title('uncertainty in the variance');

%% 
% show likelihood

bn.loglik(data)

%% 
% compare without assuming that parameters are coupled between slices
dbn = dbnet(factors,'coupled',false);
bn2 = bayesnet(dbn.unroll(7,-0.5:0.5:2.5));

%%
% show evolution of the mean and variance estimates for one variable
bn2 = bn2.learn_parameters(data);

%% 
% likelihood is a bit better without the coupling
bn2.loglik(data)

%% 
% let's check the evolution of the means and standard deviations

mus = zeros(2,2,7);
sds = zeros(2,2,7);
for s=1:2
    for j=1:7   
        mus(s,1,j) = bn2.factors{(j-1)*3+s}.mu(1);
        mus(s,2,j) = bn2.factors{(j-1)*3+s}.mu(2);        
        sds(s,1,j) = sqrt(bn2.factors{(j-1)*3+s}.sigma2(1));
        sds(s,2,j) = sqrt(bn2.factors{(j-1)*3+s}.sigma2(2));        
    end
end

figure
subplot(1,2,1);
errorbar(-0.5:0.5:2.5,squeeze(mus(1,1,:)),squeeze(sds(1,1,:)));
hold on;
errorbar(-0.5:0.5:2.5,squeeze(mus(1,2,:)),squeeze(sds(1,2,:)),'r');
title('MLO32');
legend('left attention','right attention');

subplot(1,2,2);
errorbar(-0.5:0.5:2.5,squeeze(mus(2,1,:)),squeeze(sds(2,1,:)));
hold on;
errorbar(-0.5:0.5:2.5,squeeze(mus(2,2,:)),squeeze(sds(2,2,:)),'r');
title('MRO32');
legend('left attention','right attention');

%% 
% let's see how the variables depend on their past state

betas = zeros(2,2,6);
for s=1:2
    for j=1:6   
        betas(s,1,j) = bn2.factors{j*3+s}.beta{1};
        betas(s,2,j) = bn2.factors{j*3+s}.beta{2};        
    end
end

figure
subplot(1,2,1);
plot(0:0.5:2.5,squeeze(betas(1,1,:)));
hold on;
plot(0:0.5:2.5,squeeze(betas(1,2,:)),'r');
title('MLO32');
legend('left attention','right attention');

subplot(1,2,2);
plot(0:0.5:2.5,squeeze(betas(2,1,:)));
hold on;
plot(0:0.5:2.5,squeeze(betas(2,2,:)),'r');
title('MRO32');
legend('left attention','right attention');


##### SOURCE END #####
-->
   </body>
</html>