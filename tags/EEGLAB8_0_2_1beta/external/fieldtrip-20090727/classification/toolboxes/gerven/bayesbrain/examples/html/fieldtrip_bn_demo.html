
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN">
<html xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   
      <!--
This HTML is auto-generated from an M-file.
To make changes, update the M-file and republish this document.
      -->
      <title>Using Bayesian networks together with FieldTrip data</title>
      <meta name="generator" content="MATLAB 7.6">
      <meta name="date" content="2008-10-02">
      <meta name="m-file" content="fieldtrip_bn_demo"><style>

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head>
   <body>
      <div class="content">
         <h1>Using Bayesbrain together with FieldTrip data</h1>
<pre>Create the random variables</pre><pre class="codeinput">factors = cell(1,3);
factors{1} = gaussian_cpd(1,[],3,[0; 0],{[]; []},[1; 1]);
factors{2} = gaussian_cpd(2,[],3,[0; 0],{[]; []},[1; 1]);
factors{3} = multinomial_cpd(3,[],[0.5; 0.5]);

<span class="comment">% optionally add names to the factors</span>
factors{1}.name = <span class="string">'MLO32'</span>;
factors{2}.name = <span class="string">'MRO32'</span>;
factors{3}.name = <span class="string">'orientation'</span>;
factors{3}.statenames = {<span class="string">'left attention'</span> <span class="string">'right attention'</span>};
</pre><p>Create simple bayes net</p><pre class="codeinput">bn = bayesnet(factors);
</pre><p>This is what the plot would look like</p>
         <p><img vspace="5" hspace="5" src="tmpbn.jpg"> </p>
         <p>Log likelihood of this model is pretty low since we did not train parameters</p><pre class="codeinput">bn.loglik(data)
</pre><pre class="codeoutput">
ans =

  -3.4906e+03

</pre><p>Learn parameters from complete data</p><pre class="codeinput">bn = bn.learn_parameters(data);
</pre><p>Log likelihood has increased</p><pre class="codeinput">bn.loglik(data)
</pre><pre class="codeoutput">
ans =

   -2.2308

</pre><p>Plot the estimated prior distributions with continuous ones of the form</p>
         <p><img vspace="5" hspace="5" src="fieldtrip_bn_demo_eq35319.png"> </p><pre class="codeinput">subplot(1,3,1);
bn.factors{1}.plot();
legend(<span class="string">'left attention'</span>,<span class="string">'right attention'</span>);
subplot(1,3,2);
bn.factors{2}.plot();
legend(<span class="string">'left attention'</span>,<span class="string">'right attention'</span>);
subplot(1,3,3);
bn.factors{3}.plot();
set(gcf,<span class="string">'Position'</span>,[100 100 1500 400]);
</pre><img vspace="5" hspace="2" src="fieldtrip_bn_demo_01.png"> <p>Create an inference engine</p><pre class="codeinput">ie = canonical_jtree_ie(bn);
</pre><pre class="codeoutput">triangulating model
constructing potentials
constructing junction tree
computing messages
</pre><p>Add some evidence</p><pre class="codeinput">ie.enter_evidence([nan -59.5 nan]);
</pre><p>Compute marginals</p><pre class="codeinput">m1 = normalize(ie.marginalize(1));
m3 = normalize(ie.marginalize(3));
</pre><p>Plot the marginals after evidence propagation</p><pre class="codeinput">figure
subplot(1,2,1);
m1.plot();
subplot(1,2,2);
m3.plot();
</pre><img vspace="5" hspace="5" src="fieldtrip_bn_demo_02.png"> <p class="footer"><br>
            Published with MATLAB&reg; 7.6<br></p>
      </div>
      <!--
##### SOURCE BEGIN #####
%% Using Bayesian networks together with FieldTrip data
% This example demonstrates how to use neuroimaging data obtained from FieldTrip
% together with the neurogm toolbox. In the example, we make use of covert
% attention data of one subject that has already been frequency analyzed.
% Note that this is trial based data so we can build finite size models
% that capture behaviour within a trial.
%
% The data consists of 7 different frequencies at 274 channels at time
% points [-0.5 0 0.5 1 1.5 2 2.5]. We can expect evoked response after the
% cue and alpha modulation after about 1 second
%
% In this particular example, we will construct a standard Bayesian network and
% demonstrate its use.
%
% Copyright (C) 2008  Marcel van Gerven
%

%% Compare log likelihood of a Bayesian network before/after learning
function fieldtrip_bn_demo()

%%
% Load frequency data and convert the data to a format that can be used by NEUROGM.
% A Bayesian network is a static model, so we will take out the time data
% and focus only on the 12 Hz band in two channels in left and right
% hemisphere.

load freqli; % left attention
load freqri; % right attention

% left and right channels
l = find(ismember(freqLI.label,'MLO32'));
r = find(ismember(freqRI.label,'MRO32'));

% We take the log to make the data better behaved
datal = log((squeeze(nan_mean(freqLI.powspctrm(:,[l r],3,:),4))));
datar = log((squeeze(nan_mean(freqRI.powspctrm(:,[l r],3,:),4))));
clear freqli; clear freqri;

%%
% Now we can create a very simple model that consists of one discrete
% parent (the attention condition) and two continuous children
data = [[datal ones(size(datal,1),1)]; [datar 2*ones(size(datar,1),1)]];
clear datal; clear datar;

%%
%  Create the random variables; they should follow the data ordering
factors = cell(1,3);
factors{1} = gaussian_cpd(1,[],3,[0; 0],{[]; []},[1; 1]);
factors{2} = gaussian_cpd(2,[],3,[0; 0],{[]; []},[1; 1]);
factors{3} = multinomial_cpd(3,[],[0.5; 0.5]);

% optionally add names to the factors
factors{1}.name = 'MLO32';
factors{2}.name = 'MRO32';
factors{3}.name = 'orientation';
factors{3}.statenames = {'left attention' 'right attention'};

%%
% Create simple bayes net
bn = bayesnet(factors);

%%
% Write graph structure to .ps file (requires installation of GraphViz
% library)
bn.write('tmpbn','dot','extension','ps');

%% 
% This is what the plot would look like
%
% <<tmpbn.jpg>>

%%
% Log likelihood of this model is pretty low since we did not train
% parameters
bn.loglik(data)

%%
% Learn parameters from complete data
bn = bn.learn_parameters(data);

%%
% Log likelihood has increased
bn.loglik(data)

%%
% Plot the estimated prior distributions with continuous ones of the form
%
% $$ \mathcal{N}(x; \mu_c, \sigma_c)$$
%
        
subplot(1,3,1);
bn.factors{1}.plot();
legend('left attention','right attention');
subplot(1,3,2);
bn.factors{2}.plot();
legend('left attention','right attention');
subplot(1,3,3);
bn.factors{3}.plot();
set(gcf,'Position',[100 100 1500 400]);

%%
% Create an inference engine

ie = canonical_jtree_ie(bn);

%% 
% Add some evidence

ie.enter_evidence([nan -59.5 nan]);

%%
% Compute marginals

m1 = normalize(ie.marginalize(1));
m3 = normalize(ie.marginalize(3));

%% 
% Plot the marginals after evidence propagation

figure
subplot(1,2,1);
m1.plot();
subplot(1,2,2);
m3.plot();

##### SOURCE END #####
-->
   </body>
</html>
